#include "TensorTests.cuh"

#include "../core/math/Tensor1D.cuh"
#include "../core/math/Tensor2D.cuh"
#include "../core/math/TensorOps.cuh"
#include "../core/cuda/CudaObject.cuh"
#include "../core/utils/ConsoleUtils.h"
#include "../mlp/LinearSequential.cuh"
#include "../nn/ContinuousRandomVariable.cuh"

namespace NNano
{        
    template<int N, int M, int V, int W, bool HasGrad>
    __global__  void KernelMul(const Tensor2D<N, M, HasGrad>* X, const Tensor1D<V, HasGrad>* v, Tensor1D<W, HasGrad>* w)
    {
        using TensorT = Tensor2D<N, M, HasGrad>;
        __shared__ Scratchpad<float, TensorT::kMaxConcurrency> scratch;
        Mul(*X, *v, *w, scratch);
    }

    template<int N, int M, int V, int W, bool HasGrad>
    __global__  void KernelMulT(const Tensor2D<N, M, HasGrad>* X, const Tensor1D<V, HasGrad>* v, Tensor1D<W, HasGrad>* w)
    {
        using TensorT = Tensor2D<N, M, HasGrad>;
        __shared__ Scratchpad<float, TensorT::kMaxConcurrency> scratch;
        MulT(*X, *v, *w, scratch);
    }

    template<int N, int M, int V, int W, bool HasGrad>
    __global__  void KernelMulT(const Tensor2D<N, M, HasGrad>* X, const Tensor1D<V, HasGrad>* v, Tensor1D<W, HasGrad>* w, Scratchpad<float, Tensor2D<N, M, HasGrad>::kMaxConcurrency>* scratch)
    {
        CudaAssert(scratch);
        MulT(*X, *v, *w, *scratch);
    }

    template<typename ErrType, typename RefType>
    __host__ void CheckErrorThreshold(float errVal, float threshold, const ErrType& errTensor, const RefType& refTensor, const char* message, int& errorCount, const bool verbose)
    {
        if (errVal > threshold)
        {
            printf_red("%s: FAILED (error %f)\n", message, errVal);
            std::printf("Error:\n");
            errTensor.Print();
            std::printf("Reference:\n");
            refTensor.Print();
            std::printf("\n");
            
            errorCount++;
        }
        else if(verbose)
        {
            printf_green("%s: PASSED!\n", message);
        }
    }

    __host__ void TestSquare8x8TensorMul(const bool verbose, int& errorCount)
    {
        constexpr float kErrorThreshold = 1e-6;
        constexpr int N = 8;

        Cuda::Object<Tensor2D<N, N>> X(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> v(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> r(ComputeDevice::kCUDA);        

        // NOTE: Row-major order constuctor
        X <<= Tensor2D<N, N>({ {0.652467807974029, 0.633070356251368, 0.68281308686666,
                                      0.566351831093323, 0.935202196659332, 0.976187756902101,
                                      0.238451694824191, 0.637562295790242}, {0.101098380420291,
                                      0.64552469382196, 0.159522225810158, 0.813787851275935,
                                      0.904785470451441, 0.640712457447006, 0.306539727511699,
                                      0.756197597784415}, {0.876688377753995, 0.019128400638492,
                                      0.542616681289372, 0.352370872609403, 0.899199876332835,
                                      0.968878409682844, 0.876215073712776,
                                      0.340281445182268}, {0.282418445376708, 0.296477088550717,
                                      0.695952684977098, 0.514103363052473, 0.781133951426663,
                                      0.403595994418056, 0.38515245011824,
                                      0.379794153435092}, {0.43271249281167, 0.123592882524315,
                                      0.692030134942357, 0.941189043995746, 0.0907422167282328,
                                      0.816402708208848, 0.956728218285361,
                                      0.639900147904955}, {0.957129994567048, 0.635376315590379,
                                      0.490904095442375, 0.37038068606824, 0.314276772143277,
                                      0.65659249717978, 0.301137853531729,
                                      0.847904621825146}, {0.0226571509809761, 0.163593478192408,
                                      0.694356353588249, 0.766335669320467, 0.210146094825781,
                                      0.69231648501517, 0.423810127960657,
                                      0.30261765393665}, {0.0943698123927186, 0.796860647653511,
                                      0.0290345835834827, 0.361089338620035, 0.294762947477966,
                                      0.191027881734111, 0.74805085393239, 0.549756115833064} });

        // Input vector
        v <<= Tensor1D<N>({ {0.745997562146465}, {0.490766766044425}, {0.492705416561543}, {0.52926641341919}, {0.349661831500469}, {0.515445231303594}, {0.341862603700548}, {0.310267848957651} });

        // Targets for multiply and multiply transpose
        const Tensor1D<N> targetMul({ {2.54311463071826}, {1.88756865074411}, {2.33618641198045}, {1.70185336760994}, {2.20071450422554}, {2.27809276352237}, {1.51400595076495}, {1.29472435169277} });
        const Tensor1D<N> targetMulT({ {1.79945551487407}, {1.62929517783041}, {1.96475333274066}, {2.16161456090267}, {2.35518392263892}, {2.65350477631207}, {1.83062043735004}, {2.15022972677939} });

        // Test and check errors
        KernelMul<< <1, N* N >> > (X.GetComputeData(), v.GetComputeData(), r.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        r.Download();
        const float errorMul = CwiseMax(Abs(*r - targetMul));
        CheckErrorThreshold(errorMul, kErrorThreshold, *r, targetMul, "TestSquare8x8TensorMul: mul", errorCount, verbose);

        KernelMulT << <1, N* N >> > (X.GetComputeData(), v.GetComputeData(), r.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        r.Download();
        const float errorMulT = CwiseMax(Abs(*r - targetMulT));
        CheckErrorThreshold(errorMulT, kErrorThreshold, *r, targetMulT, "TestSquare8x8TensorMul: mul transpose", errorCount, verbose);
    }


    __host__ void TestSquare4x4TensorMul(const bool verbose, int& errorCount)
    {
        constexpr float kErrorThreshold = 1e-6;
        constexpr int N = 4;

        Cuda::Object<Tensor2D<N, N>> X(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> v(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> r(ComputeDevice::kCUDA);

        // NOTE: Row-major order constuctor
        X <<= Tensor2D<N, N>({ {0.652467807974029, 0.633070356251368, 0.68281308686666, 0.566351831093323},
                                    {0.935202196659332, 0.976187756902101, 0.238451694824191, 0.637562295790242},
                                    {0.101098380420291, 0.64552469382196, 0.159522225810158, 0.813787851275935},
                                    {0.904785470451441, 0.640712457447006, 0.306539727511699, 0.756197597784415} });

        // Input vector
        v <<= Tensor1D<N>({ 0.876688377753995, 0.019128400638492, 0.542616681289372, 0.352370872609403 });

        // Targets for multiply and multiply transpose
        const Tensor1D<N> targetMul({ {1.15419222757901}, {1.19260005697745}, {0.474294186123722}, {1.23826628790775} });
        const Tensor1D<N> targetMulT({ {0.963577579819826}, {1.1497192089129}, {0.797750589019602}, {1.21674648559447} });

        // Test and check errors
        KernelMul << <1, N* N >> > (X.GetComputeData(), v.GetComputeData(), r.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        r.Download();
        const float errorMul = CwiseMax(Abs(*r - targetMul));
        CheckErrorThreshold(errorMul, kErrorThreshold, *r, targetMul, "TestSquare4x4TensorMul: mul", errorCount, verbose);

        KernelMulT << <1, N* N >> > (X.GetComputeData(), v.GetComputeData(), r.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        r.Download();
        const float errorMulT = CwiseMax(Abs(*r - targetMulT));
        CheckErrorThreshold(errorMulT, kErrorThreshold, *r, targetMulT, "TestSquare4x4TensorMul: mul transpose", errorCount, verbose);
    }

    __host__ void TestNonSquareTensorMul(const bool verbose, int& errorCount)
    {
        constexpr float kErrorThreshold = 1e-6;
        constexpr int N = 7, M = 3;

        Cuda::Object<Tensor2D<N, M>> X(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> v(ComputeDevice::kCUDA), rw(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<M>> w(ComputeDevice::kCUDA), rv(ComputeDevice::kCUDA);

        // NOTE: Row-major order constuctor
        X <<= Tensor2D<N, M>({ {0.817389490171071, 0.111419611131236, 0.789525994633852, 0.187803146706026, 0.24136096745765, 0.0657387595087811, 0.542246620509624},
                                    {0.231154506736027, 0.396006081548587, 0.700473781942245, 0.211825979054127, 0.748656881482948, 0.422850649339949, 0.247494780864008},
                                    {0.977171761740777, 0.825162939488514, 0.925275201178863, 0.578056151994379, 0.292869736797923, 0.208051064780593, 0.580474481294159} });

        // Input vector
        v <<= Tensor1D<N>({ {0.128820834638437}, {0.306427380034618}, {0.712012070075779}, {0.390581871380074}, {0.81996723678518}, {0.325351497995291}, {0.593260227507795} });
        w <<= Tensor1D<M>({ {0.518774167040164}, {0.16901301687775}, {0.472565143196439} });

        // Targets for multiply and multiply transpose
        const Tensor1D<M> targetMul({ {1.31593300106679}, {1.63088381395845}, {1.91552370181268} });
        const Tensor1D<N> targetMulT({ {0.924885985973772}, {0.514675041160793}, {0.965227685293762}, {0.406397957015768}, {0.390144622102385}, {0.203888515360294}, {0.5974453848352} });

        //X = Tensor2D<N, M>({ {1., 1., 1., 1., 1., 1., 1.}, {1., 1., 1., 1., 1., 1., 1.}, {1., 1., 1., 1., 1., 1., 1.} });
        //v = Tensor1D<N>({ {1.},{1.},{1.},{1.},{1.},{1.},{1.} });
        //w = Tensor1D<M>({ {1.},{1.},{1.} });
        //const Tensor1D<M> targetMul({ {7.},{7.},{7.} });
        //const Tensor1D<N> targetMulT({ {3.},{3.},{3.},{3.},{3.},{3.},{3.} });

        // Regular N*M
        KernelMul << <1, N* M >> > (X.GetComputeData(), v.GetComputeData(), rv.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        rv.Download();
        const float errorMul = CwiseMax(Abs(*rv - targetMul));
        CheckErrorThreshold(errorMul, kErrorThreshold, *rv, targetMul, "TestNonSquareTensorMul: mul", errorCount, verbose);

        // Transpose M*N
        KernelMulT << <1, N* M >> > (X.GetComputeData(), w.GetComputeData(), rw.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        rw.Download();
        const float errorMulT = CwiseMax(Abs(*rw - targetMulT));
        CheckErrorThreshold(errorMulT, kErrorThreshold, *rw, targetMulT, "TestNonSquareTensorMul: mul transpose", errorCount, verbose);
    }

    template<int N, int M>
    __host__ void TestLargeTensorMulImpl(const bool verbose, int& errorCount)
    {
        constexpr float kErrorThreshold = 1e-5;

        NormalRandomDistribution rng(0.f, 1.f, 0);
        //Ones rng;
        Cuda::Object<Tensor2D<N, M>> X(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> v(ComputeDevice::kCUDA), rw(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<M>> w(ComputeDevice::kCUDA), rv(ComputeDevice::kCUDA);
        using TensorT = Tensor2D<N, M>;
        constexpr int kNumThreads = TensorT::kMaxConcurrency;

        X->Initialise(rng);
        v->Initialise(rng);
        w->Initialise(rng);
        X.Upload();
        v.Upload();
        w.Upload();

        Tensor1D<M> targetMul = Mul(*X, *v);
        Tensor1D<N> targetMulT = MulT(*X, *w);       

        KernelMul << <1, kNumThreads >> > (X.GetComputeData(), v.GetComputeData(), rv.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        rv.Download();
        float errorMul = CwiseMax(Abs(*rv - targetMul));
        CheckErrorThreshold(errorMul, kErrorThreshold, *rv, targetMul, tfm::format("TestLargeTensorMul<%i, %i>: mul", N, M).c_str(), errorCount, verbose);

        //Cuda::Object<Scratchpad<float, Tensor2D<N, M>::kMaxConcurrency>> scratch(ComputeDevice::kCUDA);
        //KernelMulT << <1, kNumThreads >> > (X.GetComputeData(), w.GetComputeData(), rw.GetComputeData(), scratch.GetComputeData());

        KernelMulT << <1, kNumThreads >> > (X.GetComputeData(), w.GetComputeData(), rw.GetComputeData());

        IsOk(cudaDeviceSynchronize());
        rw.Download();
        errorMul = CwiseMax(Abs(*rw - targetMulT));
        CheckErrorThreshold(errorMul, kErrorThreshold, *rw, targetMulT, tfm::format("TestLargeTensorMul<%i, %i>: mul transpose", N, M).c_str(), errorCount, verbose);
    }

    __host__ void TestPyRef(const bool verbose, int& errorCount)
    {
        constexpr float kErrorThreshold = 1e-5;

        constexpr int N = 36, M = 36;
        Cuda::Object<Tensor2D<N, M>> X(ComputeDevice::kCUDA);
        Cuda::Object<Tensor1D<N>> v(ComputeDevice::kCUDA), rv(ComputeDevice::kCUDA);
        using TensorT = Tensor2D<N, M>;
        constexpr int kNumThreads = TensorT::kMaxConcurrency;

        X <<= Tensor2D<N, M>({
            { 0.10973151, -0.04907726, -0.01535983, 0.14746244, 0.08290981, -0.04419877, 0.12583317, -0.14565414, 0.14264466, 0.09325100, -0.12224355, -0.13593552, 0.13033764, 0.16441877, 0.01454385, -0.06512257, 0.09490214, 0.07519062, -0.02080035, 0.13343619, 0.10802908, 0.04155014, 0.08653806, -0.15611607, -0.07806812, 0.01826973, 0.04532380, -0.02278511, 0.06293124, 0.05077155, -0.15403400, 0.05256970, -0.01355088, -0.11469090, 0.00562467, -0.04098988 },
            { -0.08850666, -0.15187284, 0.13942714, -0.10121608, 0.02238519, 0.13351665, -0.02099709, -0.10923567, -0.16124295, 0.02769226, -0.08362703, 0.01215433, 0.05323686, -0.04722240, 0.11300813, -0.02168840, -0.06651449, -0.11019963, 0.05056696, -0.10304251, 0.03503476, -0.02103497, 0.11454250, -0.08170722, -0.08210371, -0.02153911, -0.10179695, 0.06354065, -0.06104986, 0.06837922, 0.09672879, 0.09732248, -0.03059687, 0.09095605, -0.08825468, -0.16605823 },
            { -0.01586165, -0.12084445, -0.12912135, 0.04236603, 0.14242066, -0.06558889, -0.00942796, -0.12074908, 0.02912955, 0.04751617, -0.02558421, 0.12680490, -0.13413791, -0.02236144, -0.09251174, 0.14634337, 0.14116909, 0.16394232, 0.15334071, 0.06600945, -0.12761909, -0.11305265, 0.03995389, -0.14880054, 0.10551392, 0.07245712, 0.03976576, -0.14547035, 0.12124135, -0.01763926, -0.06993964, 0.08701833, 0.01408428, -0.07414006, 0.03900884, -0.11114299 },
            { 0.15490235, 0.14608289, 0.07686365, 0.08817129, -0.16567618, -0.09264791, -0.16037786, -0.08686765, -0.13817900, 0.12267859, 0.08991872, 0.09815218, -0.07398915, 0.12703119, -0.02408330, -0.04318144, 0.08973874, 0.11037190, -0.11978843, 0.15867157, -0.01682158, 0.04439002, -0.16595611, 0.01855426, -0.08248603, -0.10435679, -0.06958769, -0.00077635, -0.04748021, -0.10676569, 0.11933078, 0.04958320, -0.15510742, 0.03496127, 0.04094152, 0.00612426 },
            { 0.04047094, -0.01395406, 0.07289045, -0.11732994, -0.07106362, 0.12485103, -0.10325676, 0.08177191, 0.15421207, -0.15240179, -0.07301744, 0.14222904, -0.01007783, 0.03290226, 0.02371992, 0.06868319, -0.06867194, 0.02163704, 0.11353017, -0.01406044, -0.15290937, 0.05760922, -0.04254767, -0.03516142, 0.08692254, 0.02920891, -0.10082535, -0.07691173, -0.02533494, -0.04117753, -0.03528328, -0.11391817, 0.12073772, 0.08643697, 0.03289099, 0.03773689 },
            { 0.01951136, 0.12462236, 0.03771351, 0.02538867, -0.09161850, 0.05559857, -0.15592444, 0.05256474, -0.14446490, -0.06897863, 0.08798976, -0.09926867, 0.13271220, -0.09208673, 0.15786515, 0.05136867, -0.07222569, 0.10164650, -0.14759879, -0.10558181, -0.10441832, 0.02193999, 0.01637383, -0.14335120, 0.16082679, -0.00015928, -0.08899945, 0.00398104, -0.07154223, 0.04598200, 0.06033488, -0.04727685, 0.00971635, 0.09916802, -0.10840522, -0.03716467 },
            { -0.02458744, -0.11026882, 0.01357454, 0.00612544, -0.13462144, 0.03418948, 0.15907775, 0.08864896, -0.09040634, 0.15256111, -0.11456567, -0.08474096, 0.07351552, 0.13259025, 0.15904768, 0.14348741, -0.09177428, 0.03813778, -0.10465235, 0.00368054, 0.13808416, 0.08206528, -0.15389565, -0.07172877, -0.14062351, 0.07851189, -0.02115750, -0.12183716, -0.05325733, 0.05469406, 0.01542993, 0.15638454, -0.00221275, 0.05242614, -0.05048784, 0.01988800 },
            { 0.00597058, 0.14316355, 0.06983508, -0.09498201, -0.14809291, -0.15857315, -0.06052637, 0.02154420, 0.15679435, -0.01637577, 0.06516512, 0.08470424, -0.12766674, -0.13786927, 0.06315267, 0.07768488, -0.07760587, 0.02611803, -0.16318516, 0.00210078, 0.04085380, 0.00157760, -0.02645499, 0.06937160, -0.04581110, 0.12406562, -0.14355491, -0.09524947, -0.13913882, -0.15073375, 0.12355889, -0.04124548, -0.13092116, 0.03456827, -0.12620930, 0.00861555 },
            { 0.07923035, -0.03524278, 0.08567934, 0.03420745, -0.13374005, 0.03280300, 0.10744025, -0.03863662, 0.01575154, 0.02126235, 0.01433201, 0.04332481, -0.15957654, 0.12645255, 0.07269083, 0.02058177, 0.03032668, -0.13441132, -0.04758682, -0.00724946, 0.03961821, -0.09142649, 0.01768406, -0.05172461, 0.12131326, -0.14306021, 0.01742214, 0.11291577, -0.12944703, -0.00477690, 0.07701544, 0.06725420, 0.01960003, 0.06737264, -0.11618280, 0.13881423 },
            { 0.00371720, 0.10773458, 0.03686999, -0.01854123, 0.07138957, 0.15821676, 0.16440280, -0.14029104, 0.01010823, -0.11972938, 0.09710808, 0.11964907, -0.11703293, -0.00963260, 0.11532976, 0.11021779, -0.12531160, 0.11190505, -0.02950658, -0.14174537, 0.03319985, 0.07764369, 0.09995349, -0.11332049, -0.12071377, -0.11198187, 0.09445204, -0.14566353, -0.00140542, -0.04897680, 0.07276744, 0.03273065, -0.08416259, 0.02911110, 0.15337797, 0.02744061 },
            { -0.08259068, 0.00557999, -0.15287457, -0.10693268, -0.03095800, -0.10385861, 0.14113583, 0.03235172, 0.12909044, -0.03795148, -0.02317919, 0.04204088, -0.04955660, -0.05681215, -0.16349593, 0.12555780, 0.15083818, -0.16502039, -0.05514308, -0.12606466, -0.06765425, 0.12688513, 0.08915348, -0.01293200, 0.07118362, 0.04977345, 0.09101959, -0.13393340, 0.05151786, -0.15784886, -0.10961092, -0.06210902, -0.01623823, -0.15728413, 0.00414787, 0.02660942 },
            { -0.06614435, 0.05405886, 0.14563723, -0.02846910, -0.08876310, -0.14763807, -0.12170047, -0.09218125, -0.12321238, -0.06552505, 0.09181415, 0.05215369, 0.15022068, 0.16547449, -0.06001781, -0.06526985, 0.02280749, -0.13271371, 0.09065317, -0.02999632, -0.13955483, -0.12583028, -0.11484472, 0.04580869, 0.12776174, 0.13204212, -0.04589250, -0.09680933, -0.07397249, -0.11385324, -0.04297028, -0.15052371, 0.08908291, -0.15686588, -0.10367577, 0.11185004 },
            { -0.12466820, 0.03984411, 0.12483729, 0.16428562, 0.08433162, -0.04472767, 0.09523924, -0.00550045, -0.05139004, 0.00054280, 0.03738485, 0.11175330, 0.06996070, 0.07958174, 0.02493292, -0.00838859, 0.06998281, 0.04008706, -0.15948170, 0.02694587, -0.07401532, -0.08838298, 0.06445505, 0.03408144, 0.02822389, -0.07906391, 0.07701235, 0.15640529, 0.02038951, 0.06850439, -0.14622134, 0.09908254, 0.05789800, 0.07508801, 0.06950206, -0.04383743 },
            { -0.01000418, 0.16121127, 0.12195601, -0.11946474, 0.13223727, 0.16587193, 0.02191855, -0.13003036, 0.03230678, -0.03366013, 0.11983116, -0.16013068, 0.04265058, -0.00195481, 0.01312047, 0.11464866, 0.00301079, -0.13418013, -0.09722291, -0.06673398, 0.01777506, 0.06431665, -0.03110947, -0.06577969, 0.07313438, -0.16205132, 0.11646356, -0.01937453, 0.11597155, 0.12593566, 0.01780449, 0.05272122, -0.09426775, 0.11941402, 0.09754919, -0.02617647 },
            { 0.06496286, -0.00933553, 0.13021500, 0.06860749, 0.12150784, -0.15149650, 0.16238780, 0.06209689, 0.08103032, 0.03713821, 0.10946451, 0.15690358, -0.01419841, -0.13675338, 0.15304388, -0.03514858, -0.08037937, 0.10259761, 0.09301309, 0.02231370, -0.01046205, -0.03188348, 0.15281828, 0.10154746, 0.09925599, 0.10627969, -0.08722655, 0.03479920, -0.14418161, 0.09682991, -0.16520129, -0.16656737, -0.16474700, 0.10277791, 0.01734500, 0.00037901 },
            { 0.02650912, -0.06307521, -0.05061056, -0.11226535, -0.04070282, -0.10255609, 0.00438510, 0.13095106, -0.13778204, 0.08196189, -0.12396634, -0.06905399, 0.03259073, 0.02867787, 0.13667934, -0.00006235, -0.06347807, -0.06892805, 0.00488633, -0.12497147, -0.13067639, -0.07131054, 0.00428139, -0.11255686, -0.09513887, 0.11899920, 0.15401982, -0.05220588, -0.14298961, -0.06380892, 0.06726705, 0.05409081, -0.05166662, -0.14678657, -0.05011468, -0.03726579 },
            { 0.09597714, -0.08264500, 0.10002749, 0.02311975, -0.02793305, -0.14853001, 0.16454454, -0.02971947, 0.10486643, -0.08621141, -0.16230512, -0.13285033, -0.08541422, -0.05307804, -0.02353556, 0.13900240, -0.15370975, 0.08318610, 0.14023812, 0.00107270, -0.10394035, 0.00533070, 0.03953981, 0.07374346, -0.05066153, -0.05719523, -0.07862847, -0.16120236, 0.05853480, -0.12600248, -0.08006692, -0.00171512, 0.12848403, 0.14818932, -0.12122669, 0.14454783 },
            { 0.14929684, 0.13463934, 0.01451035, 0.13385765, 0.08097766, -0.11959326, -0.08784620, 0.00313444, -0.11811326, -0.05488032, 0.13437362, 0.07759659, 0.14514656, 0.00127770, -0.08498347, 0.11030801, 0.01228704, 0.02806729, -0.07061633, 0.06846182, -0.12309104, 0.13299610, 0.14580713, 0.06013702, 0.12978770, 0.10116138, -0.06365290, -0.14455557, 0.02193169, 0.10464604, -0.01705025, 0.01402354, 0.12353219, 0.06881541, 0.12459831, 0.02447289 },
            { 0.01868246, -0.03986625, -0.02812476, -0.08857761, 0.11142947, 0.15200819, 0.06185250, 0.00473563, -0.05501752, -0.16455531, -0.03086092, -0.11831771, -0.12304370, -0.03300273, -0.03278683, 0.03362095, -0.12080326, 0.11977644, -0.15174192, -0.07893221, -0.06327530, 0.01027553, 0.06889679, -0.04392199, 0.02601148, -0.03945585, -0.06555168, -0.02331281, 0.03355698, -0.16189185, -0.11600721, 0.13020854, 0.07536416, -0.00445627, 0.00526339, 0.02300584 },
            { 0.03873704, -0.11378972, -0.04543126, -0.15296265, -0.13103096, -0.03135921, -0.02200615, 0.13035770, 0.02870756, -0.02702428, -0.00461741, 0.09308206, -0.05048746, -0.03115730, -0.03343450, -0.13439548, -0.02329378, -0.15407363, -0.08958642, -0.10608564, 0.12415431, -0.15353070, 0.16058864, 0.06249124, -0.11263222, 0.13808160, -0.03672659, -0.14116418, -0.02314536, 0.08236836, -0.16204815, -0.01248969, 0.06781386, -0.06495422, 0.01517963, -0.06532048 },
            { -0.11181631, 0.13052346, -0.11834129, -0.00195396, 0.05550997, -0.09314134, 0.08047360, -0.13840982, 0.15917517, 0.07422648, -0.02359565, -0.13863990, 0.00513981, 0.05911821, -0.09051824, -0.02098937, -0.16609608, -0.16661716, -0.01810075, 0.13945760, -0.00784425, 0.05225199, -0.06661930, -0.05442111, -0.01831974, -0.08425530, 0.10198571, 0.10393320, -0.12956676, 0.05111986, -0.06885084, -0.09584068, -0.02033307, -0.05169372, -0.09489839, 0.02456267 },
            { 0.09512894, -0.02571779, -0.01165853, 0.01254182, -0.07162975, 0.08823524, 0.15377976, -0.01523268, 0.01132967, 0.13428937, 0.13650985, -0.12398335, -0.07718377, -0.16348819, 0.10208191, 0.13008390, -0.06066024, 0.05346225, 0.04037236, -0.14339297, 0.06655560, 0.08178020, 0.00366540, 0.01709168, 0.03872906, 0.12006803, 0.14726175, 0.02395450, 0.07104278, -0.04360428, 0.09936740, -0.06555860, -0.13738152, 0.07819575, 0.06181443, 0.03668463 },
            { 0.07091142, 0.01983277, 0.05672316, 0.06791383, -0.08990773, -0.00893003, 0.02511694, -0.02530383, -0.14013067, 0.01580988, 0.10185669, -0.08913308, 0.16363479, 0.03800951, 0.07088445, -0.06435756, -0.13633549, -0.06202672, 0.00509197, -0.07594562, 0.14842774, -0.10667227, -0.11225420, -0.05911762, 0.14952533, -0.07620917, 0.15418862, 0.08009477, -0.02532382, 0.08620133, 0.07923472, -0.08483200, -0.03431244, 0.16143744, 0.09555341, -0.08140342 },
            { -0.04481483, 0.09341533, 0.08461092, 0.01321132, -0.10724054, -0.12292767, -0.03517818, 0.06127785, -0.01776837, -0.13934708, -0.04084659, 0.16636099, -0.13775322, -0.12934922, 0.10477160, 0.16583450, -0.16032717, -0.15073976, -0.05211429, 0.16617249, -0.09459275, 0.01424992, 0.13605447, -0.05900149, -0.05111091, -0.11187222, 0.00639926, 0.15556307, 0.06815214, 0.11714835, -0.01104188, -0.02647309, -0.02977568, 0.09505780, -0.02185464, -0.14236596 },
            { -0.05852471, 0.06522584, 0.16249554, -0.03030539, -0.14511065, -0.12271965, -0.13113444, 0.06718391, 0.12285478, 0.04928911, 0.05746581, 0.10858007, 0.11395340, 0.09952207, 0.09319998, 0.04509830, 0.08602719, -0.11436087, -0.10787581, 0.04482377, 0.02593702, -0.14652035, -0.12141639, -0.13267922, 0.13237067, 0.10896643, -0.08772507, 0.02514683, -0.03833455, 0.14488770, -0.15095580, -0.12159004, -0.13876086, 0.09699641, -0.08331460, 0.09926833 },
            { 0.05633874, -0.08146542, -0.04489838, -0.06744711, 0.07352905, -0.06683870, 0.05656151, 0.01190662, -0.13310108, -0.10476866, -0.11556230, 0.08733247, 0.03611355, -0.00419067, -0.09924021, -0.16513458, -0.05898106, -0.12755708, -0.16577730, -0.15896004, -0.10886574, -0.16202345, 0.05195428, 0.06236209, 0.06717797, -0.16591582, 0.10305990, 0.03249393, 0.08522306, -0.04096280, 0.08003576, -0.15806918, 0.05676788, 0.13216062, 0.07006091, -0.15710215 },
            { -0.04678725, -0.02069734, 0.08732565, -0.06306702, 0.02397113, -0.05850848, -0.02647640, -0.00331771, -0.09570275, -0.11568224, 0.13758953, 0.14003320, -0.00504579, 0.14426149, 0.12843095, -0.10498025, -0.06622650, -0.11447450, 0.05388494, 0.00421502, -0.02285618, 0.12374450, -0.06514508, -0.09121516, -0.11847936, -0.08478819, 0.16063811, -0.08103176, -0.04585888, 0.07511906, -0.12800549, -0.10115977, 0.12266804, -0.06392384, -0.08648455, -0.02156305 },
            { -0.02374870, 0.03045893, 0.06110354, -0.12850770, 0.15146030, -0.15845887, 0.05644746, -0.04702606, -0.07038260, 0.15590341, -0.16060887, 0.01138265, 0.10679744, 0.14899902, -0.14090255, 0.02008064, 0.16489665, -0.16325484, 0.04070866, -0.10442849, 0.02705611, -0.15076408, 0.08200057, -0.03697319, 0.09960715, -0.00250626, -0.02375661, -0.04046386, -0.15260687, -0.07079349, 0.00553507, -0.12894109, 0.14626683, -0.10839431, -0.06493201, -0.02228814 },
            { -0.13501045, -0.00131680, -0.08025720, -0.13950650, 0.00408809, 0.14754806, 0.04104155, 0.13746493, -0.00162987, -0.05817318, 0.13432635, -0.08875299, -0.15418419, 0.03647713, 0.08306246, -0.09962746, 0.05866073, -0.05913053, -0.02022223, -0.03690301, -0.03564878, -0.13561055, 0.04084726, -0.04384063, 0.12743928, 0.02781856, -0.13630353, -0.12679237, -0.08686060, 0.07981287, -0.10760760, -0.07624549, 0.03025825, -0.11554965, -0.08207089, 0.15113087 },
            { -0.08811562, -0.05552863, 0.11920010, 0.03734736, 0.13081659, -0.14683166, 0.08330758, -0.02549298, -0.10677439, -0.07138275, -0.16121237, 0.11529587, -0.03198020, -0.16342407, 0.14253612, 0.10795088, 0.06891377, 0.16312172, 0.15050901, 0.15575977, 0.14925428, 0.13544624, 0.04363151, -0.01395760, 0.00633822, -0.06926294, 0.07830961, 0.00482844, 0.03932101, -0.10735794, -0.06275475, 0.12495045, 0.01621024, 0.05751531, -0.14550124, -0.07137102 },
            { -0.00424176, -0.01748925, 0.10639082, -0.05029746, 0.13909955, -0.03223462, 0.06482482, -0.11733800, 0.02828890, -0.16248950, -0.14299810, -0.10666754, 0.04665948, 0.01291783, 0.01613075, -0.01823141, 0.14004160, 0.16326667, 0.07078141, 0.13254251, -0.00823700, -0.06127197, 0.03240155, 0.10958929, -0.02575861, -0.12797198, 0.05503933, -0.04248595, -0.08022861, 0.10527040, -0.00565703, -0.09527080, -0.09972869, 0.15696006, 0.10840793, -0.11950980 },
            { 0.00007968, -0.00360578, 0.07944404, -0.14274377, 0.00247703, 0.05553170, 0.08481719, 0.01742716, -0.08261180, -0.16000244, 0.09008558, 0.15216054, -0.05031997, -0.14894234, 0.04876430, -0.11684977, -0.10889417, 0.04543097, -0.01582710, -0.01133676, 0.14949138, -0.02923371, 0.10145168, -0.05187057, 0.12401737, 0.05084540, 0.14851637, 0.05812991, -0.05903625, 0.07264231, 0.14199640, 0.03158887, 0.07683812, -0.11725388, 0.09030606, -0.15754817 },
            { 0.14733692, 0.06883729, 0.01096807, -0.15599221, 0.15156020, 0.10627355, 0.15364476, 0.06551848, 0.05612959, -0.04317224, -0.06830029, 0.06606716, 0.05780089, -0.00540334, 0.02650976, 0.05725227, -0.16105944, -0.14739059, -0.04436731, 0.11351000, 0.08131371, -0.15907699, -0.05004144, -0.01761754, 0.05474018, 0.13635354, 0.00364526, -0.12973100, 0.01022650, -0.06436016, -0.10185699, 0.09231503, -0.02239199, 0.07875301, 0.12977637, 0.01638027 },
            { 0.09387477, -0.07871424, 0.09303595, 0.00665838, 0.11075492, 0.15934326, -0.12607573, 0.15822016, 0.12722699, -0.13426149, 0.04885691, -0.13568465, 0.05406435, 0.02577333, -0.15910190, 0.06050314, -0.04578005, 0.16612954, 0.16266800, 0.05753501, 0.13137384, 0.06019677, 0.15768297, -0.01538777, 0.04119174, -0.02753049, -0.00291473, -0.05027773, -0.06595914, 0.09641297, 0.07152118, -0.07357298, -0.14688359, 0.08149289, -0.15331195, -0.00737520 },
            { -0.14340714, 0.13955514, 0.13571282, -0.13697365, -0.15495554, -0.09854120, 0.04599021, -0.08334599, -0.03969102, -0.04224654, 0.03057216, -0.07883430, 0.07580249, -0.11926447, -0.01483564, 0.13970439, -0.09202977, 0.12786974, 0.08674334, -0.05383637, 0.05779408, -0.11259598, 0.01341377, 0.04721010, 0.14416023, -0.09326315, -0.09478700, -0.08318415, -0.16236208, 0.03370458, -0.13796166, -0.04474066, -0.07436359, 0.00931852, 0.05055813, -0.12111428 },
            { -0.04920244, -0.01602314, -0.09634706, 0.03850192, 0.06169939, -0.11878020, 0.13105275, 0.11843331, -0.05007076, 0.02479857, 0.02029300, -0.02299535, -0.11185634, 0.13733675, 0.08201717, -0.13927814, -0.12916929, 0.15849249, 0.02660082, -0.03829093, 0.11295630, 0.04787983, 0.05982848, 0.13222320, -0.01300798, 0.15881254, -0.11707245, -0.10141669, 0.02823974, -0.02023412, 0.09510858, -0.04532119, 0.02620804, -0.03463133, 0.12512441, -0.01093209 }
            });

        v <<= Tensor1D<N>({ -0.02777778, -0.02777778, 0.02777778, 0.02777778, 0.02777778, 0.02777778, -0.02777778, -0.02777778, 0.02777778, 0.02777778, 0.02777778, 0.02777778, -0.02777778, -0.02777778, -0.02777778, 0.02777778, 0.02777778, 0.02777778, -0.02777778, -0.02777778, -0.02777778, 0.02777778, 0.02777778, 0.02777778, -0.02777778, -0.02777778, -0.02777778, 0.02777778, 0.02777778, 0.02777778, -0.02777778, -0.02777778, -0.02777778, 0.02777778, 0.02777778, 0.02777778 });

        const Tensor1D<N> targetMulT({ {0.00577586962873619}, {0.0097661335590684}, {-0.0054056790435654},
            {0.0115913437050852}, {-0.0211853869726086}, {-0.0142188889152888},
            {-0.0135175919147406}, {0.0069830580586446}, {-0.0179151117109866},
            {-0.000939979797420599}, {0.0085170987369234}, {-0.0031640191420104},
            {-0.0150105573119556}, {-0.0024166454711094}, {-0.007492632543855},
            {0.0334327854524004}, {0.0072111972435624}, {0.0225515304152334},
            {0.0373094138180862}, {-0.011853305114931}, {-0.0209946733462404},
            {0.0104517197250264}, {0.006536231078454}, {-0.0034372999972062},
            {0.0281679447534354}, {0.000461424481358404}, {-0.0085424237389494},
            {-0.021550078112895}, {-0.0022167746217864}, {-0.0260418156944562},
            {0.0221244251032872}, {-0.011431575914526}, {0.007068060287667},
            {-0.0083251995549048}, {-0.0088507190413908}, {0.018583170931098} });

        KernelMulT << <1, kNumThreads >> > (X.GetComputeData(), v.GetComputeData(), rv.GetComputeData());
        IsOk(cudaDeviceSynchronize());
        rv.Download();
         
        //MulT(*X, *v, *rv);

        float errorMulT = CwiseMax(Abs(*rv - targetMulT));
        CheckErrorThreshold(errorMulT, kErrorThreshold, *rv, targetMulT, tfm::format("TestPyRef<%i, %i>", N, M).c_str(), errorCount, verbose);
    }

    __host__ void TestLargeTensorMul(const bool verbose, int& errorCount)
    {        
        TestLargeTensorMulImpl<36, 36>(verbose, errorCount);
        TestLargeTensorMulImpl<17, 29>(verbose, errorCount);
        TestLargeTensorMulImpl<27, 31>(verbose, errorCount);
        TestLargeTensorMulImpl<32, 32>(verbose, errorCount);
        TestLargeTensorMulImpl<7, 68>(verbose, errorCount);
        TestLargeTensorMulImpl<1, 55>(verbose, errorCount);
        TestLargeTensorMulImpl<87, 1>(verbose, errorCount);
        
        TestLargeTensorMulImpl<36, 38>(verbose, errorCount);
        TestLargeTensorMulImpl<80, 40>(verbose, errorCount);
        TestLargeTensorMulImpl<49, 36>(verbose, errorCount);
        TestLargeTensorMulImpl<49, 49>(verbose, errorCount);

        TestPyRef(verbose, errorCount);

        //using Model = LinearSequential<Linear<36, 80>, Linear<80, 40>, Linear<40, 35>, Linear<35, 27>>;

    }

    __host__ void RunTensorTests(const bool verbose)
    {
        int errorCount = 0;
        
        /*TestSquare4x4TensorMul(verbose, errorCount);
        TestSquare8x8TensorMul(verbose, errorCount);
        TestNonSquareTensorMul(verbose, errorCount);*/
        TestLargeTensorMul(verbose, errorCount);

        AssertFmt(errorCount == 0, "Test failed with %i errors", errorCount);

        if (verbose) { printf_green("All tensor tests okay!\n"); }
    }

}